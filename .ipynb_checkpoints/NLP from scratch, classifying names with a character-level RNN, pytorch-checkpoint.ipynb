{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Arabic.txt', 'data/names/Chinese.txt', 'data/names/Czech.txt', 'data/names/Dutch.txt', 'data/names/English.txt', 'data/names/French.txt', 'data/names/German.txt', 'data/names/Greek.txt', 'data/names/Irish.txt', 'data/names/Italian.txt', 'data/names/Japanese.txt', 'data/names/Korean.txt', 'data/names/Polish.txt', 'data/names/Portuguese.txt', 'data/names/Russian.txt', 'data/names/Scottish.txt', 'data/names/Spanish.txt', 'data/names/Vietnamese.txt']\n",
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,:'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# print(readLines('data/names/Chinese.txt'))\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ang', 'AuYong', 'Bai', 'Ban', 'Bao']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['Chinese'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Names into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# ,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    \"\"\"Turn a line into a <line_length x 1 x n_letters> Tensor\"\"\"\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "print(lineToTensor('Jones'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        print('input:', input, input.size())\n",
    "        print('hidden', hidden, hidden.size())\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        print('combined', combined)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(RNN, self).__init__()\n",
    "\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "#         self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input, hidden):\n",
    "#         combined = torch.cat((input, hidden), 1)\n",
    "#         hidden = self.i2h(combined)\n",
    "#         output = self.i2o(combined)\n",
    "#         output = self.softmax(output)\n",
    "#         return output, hidden\n",
    "\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "# n_hidden = 128\n",
    "# rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8803, -2.8161, -2.8097, -2.9276, -2.8146, -2.9399, -2.9498, -2.9254,\n",
      "         -2.8016, -2.9163, -2.8655, -2.9133, -2.9539, -2.8627, -2.9376, -2.8708,\n",
      "         -2.9062, -2.9600]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = letterToTensor('A')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8803, -2.8161, -2.8097, -2.9276, -2.8146, -2.9399, -2.9498, -2.9254,\n",
      "         -2.8016, -2.9163, -2.8655, -2.9133, -2.9539, -2.8627, -2.9376, -2.8708,\n",
      "         -2.9062, -2.9600]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Irish', 8)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Dutch / line = Prinsen\n",
      "category = Portuguese / line = Pinheiro\n",
      "category = Japanese / line = Deguchi\n",
      "category = Japanese / line = Kawate\n",
      "category = French / line = Romilly\n",
      "category = Italian / line = Santini\n",
      "category = German / line = Ott\n",
      "category = French / line = St pierre\n",
      "category = Spanish / line = Puerta\n",
      "category = Chinese / line = Loong\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_tensor[i]: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "hidden: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450], requires_grad=True) \n",
      " tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "line_tensor[i]: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "hidden: tensor([[ 0.0103,  0.0780, -0.0343, -0.0048, -0.0211, -0.0147,  0.0463,  0.1284,\n",
      "          0.0789, -0.0282,  0.0170, -0.0725, -0.0405,  0.0133,  0.0002,  0.0041,\n",
      "         -0.0588,  0.0314, -0.0747, -0.0562,  0.0283, -0.1092, -0.0529, -0.0354,\n",
      "         -0.0413, -0.0171, -0.0558, -0.0808, -0.0156, -0.0675,  0.0378,  0.0942,\n",
      "         -0.0459,  0.1163,  0.1175,  0.0621, -0.1284,  0.0472, -0.1180,  0.0590,\n",
      "         -0.0817, -0.0076,  0.0402,  0.0210, -0.0139,  0.0470,  0.0875, -0.0661,\n",
      "         -0.0331,  0.0614,  0.0332,  0.0222,  0.0104,  0.0591,  0.0583, -0.0216,\n",
      "          0.0267, -0.0509,  0.0466, -0.0621,  0.0288,  0.0119,  0.1066,  0.0691,\n",
      "          0.0341, -0.0524, -0.0064, -0.0049,  0.0881, -0.1179, -0.0548,  0.0254,\n",
      "         -0.1317,  0.0227, -0.0615,  0.0086, -0.0203,  0.0174,  0.0710,  0.1053,\n",
      "          0.1029, -0.0051, -0.0347,  0.0313,  0.0123,  0.0027,  0.0176,  0.0333,\n",
      "         -0.0922, -0.0082, -0.0405,  0.0025,  0.0451, -0.0187,  0.0161, -0.0265,\n",
      "         -0.0596,  0.0040,  0.1058,  0.0992,  0.0747,  0.0456, -0.1231, -0.0566,\n",
      "          0.0674,  0.0715, -0.0783, -0.0775,  0.0694,  0.0394,  0.0023, -0.0115,\n",
      "          0.0199, -0.0073,  0.0615,  0.0351, -0.0744,  0.1060, -0.1173, -0.0181,\n",
      "         -0.0032, -0.0009,  0.1193, -0.0405,  0.0507,  0.0134,  0.0160, -0.0289]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450], requires_grad=True) \n",
      " tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "line_tensor[i]: tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "hidden: tensor([[ 2.0607e-01,  5.0058e-02, -8.7082e-02,  5.5992e-02, -8.5000e-02,\n",
      "          9.4028e-02,  2.7045e-02,  1.4444e-01, -5.0745e-02, -2.9941e-02,\n",
      "         -1.1599e-01, -1.0489e-01,  6.2447e-03,  3.4023e-02, -1.1479e-02,\n",
      "          6.6523e-03, -7.4436e-02, -6.2163e-02, -9.1954e-02,  2.9550e-03,\n",
      "         -3.8360e-02, -5.7866e-02, -5.7361e-02, -7.0772e-03,  4.3807e-02,\n",
      "          2.3397e-02, -9.9314e-02, -2.5314e-02, -3.5283e-02, -4.9716e-02,\n",
      "         -5.8445e-02,  4.0414e-03, -4.0497e-02,  8.2697e-02,  5.8423e-02,\n",
      "         -4.9023e-02, -2.2505e-02, -1.2053e-01, -1.3751e-01, -3.6611e-02,\n",
      "         -2.2699e-02, -4.4757e-02,  7.7712e-02,  5.4079e-02, -1.1948e-02,\n",
      "          3.0775e-02,  6.5136e-02, -7.1938e-02, -1.0518e-02,  9.5420e-02,\n",
      "          1.5601e-01, -7.0203e-02, -1.0360e-01, -2.2544e-03,  2.3574e-02,\n",
      "          1.2831e-04, -2.0404e-02, -3.5717e-02,  6.3912e-02,  4.7516e-02,\n",
      "          4.7525e-03,  1.0529e-02,  1.2491e-01, -2.7784e-02, -4.1276e-02,\n",
      "         -8.9244e-02,  2.6848e-02, -1.3705e-01,  4.9590e-02, -1.0405e-01,\n",
      "          6.8861e-02,  5.8517e-02, -9.1194e-04, -2.4468e-02, -5.3646e-03,\n",
      "          1.0666e-01,  6.7395e-04,  7.5943e-02,  8.2093e-04,  1.5790e-01,\n",
      "          8.6578e-03, -1.3161e-01, -2.8583e-02,  1.2310e-01,  6.8826e-02,\n",
      "         -4.5627e-02,  7.8144e-02,  3.4464e-02,  5.4212e-02, -9.1522e-02,\n",
      "          5.1562e-03,  1.2695e-01, -1.6187e-02,  2.2518e-02, -4.4459e-02,\n",
      "          3.1808e-02,  3.2104e-02, -5.0275e-03, -2.3383e-02,  3.6424e-02,\n",
      "          4.0623e-02,  1.3188e-01, -7.0314e-02, -7.0168e-02,  4.1846e-02,\n",
      "          6.7058e-02, -7.2705e-03, -7.4358e-02, -9.9864e-02, -1.4386e-01,\n",
      "         -8.3649e-03,  3.7017e-02,  1.6143e-02,  2.8190e-02, -7.8874e-03,\n",
      "         -6.5497e-02, -9.7111e-02,  3.8073e-02, -9.5389e-02,  6.8615e-02,\n",
      "          2.7550e-02, -5.4349e-02,  8.1750e-02, -1.5295e-04,  7.1776e-02,\n",
      "          8.9753e-02,  1.0604e-01, -1.3924e-01]], grad_fn=<AddmmBackward>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450], requires_grad=True) \n",
      " tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "line_tensor[i]: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "hidden: tensor([[ 0.1466,  0.0016, -0.0273, -0.0929,  0.0246,  0.0490,  0.0316,  0.0043,\n",
      "         -0.0892,  0.0065,  0.0104,  0.0105,  0.1002, -0.0497,  0.0159, -0.0445,\n",
      "         -0.1015, -0.0733, -0.0018,  0.0444, -0.0507, -0.0977, -0.0765,  0.0562,\n",
      "          0.0255,  0.0926, -0.1112,  0.0881,  0.0329, -0.0468, -0.1404,  0.0597,\n",
      "          0.0013,  0.0814,  0.0252,  0.0794, -0.0505, -0.0331, -0.1116, -0.0510,\n",
      "          0.0546,  0.0622,  0.1368,  0.0048, -0.0467,  0.0354,  0.0672, -0.1760,\n",
      "         -0.0084, -0.0179,  0.0553, -0.0910, -0.1300,  0.0713,  0.0914, -0.0052,\n",
      "          0.0784, -0.0436, -0.0100, -0.1233,  0.0296,  0.0430,  0.0238, -0.0177,\n",
      "          0.0656, -0.1485, -0.0080, -0.1226, -0.0281, -0.0893,  0.0705,  0.0152,\n",
      "          0.0398, -0.0175,  0.0360,  0.0424,  0.1300,  0.1373, -0.0426,  0.0497,\n",
      "          0.0629, -0.0051,  0.0226,  0.0200,  0.0762,  0.0592,  0.1455,  0.0977,\n",
      "         -0.0316, -0.0034,  0.0390,  0.0796,  0.0692,  0.0263, -0.0267, -0.0248,\n",
      "          0.0684,  0.1006,  0.0107,  0.0794,  0.0026,  0.1330, -0.0618, -0.0457,\n",
      "         -0.0701,  0.0256, -0.0759, -0.0678,  0.0287, -0.0700, -0.0671, -0.0198,\n",
      "          0.0690,  0.0642, -0.0960,  0.0299, -0.0583,  0.0748, -0.0847,  0.0086,\n",
      "         -0.0237, -0.0846,  0.1689, -0.0333,  0.0177,  0.0582, -0.0289, -0.0277]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450], requires_grad=True) \n",
      " tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "line_tensor[i]: tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "hidden: tensor([[ 0.0569,  0.1290, -0.0623, -0.0136, -0.0261, -0.0297,  0.0521,  0.0989,\n",
      "         -0.1428, -0.0776, -0.0550, -0.0079, -0.0663, -0.0906, -0.1213, -0.0056,\n",
      "         -0.0596, -0.0839, -0.0041, -0.0171, -0.1277, -0.0775, -0.0108, -0.0183,\n",
      "          0.0060,  0.1090, -0.0182,  0.0893,  0.0274,  0.0212,  0.0489, -0.0074,\n",
      "          0.0471,  0.0520,  0.0379,  0.0541, -0.1251, -0.0931, -0.0236, -0.0492,\n",
      "          0.0341,  0.0761,  0.0191,  0.0105,  0.0975, -0.0690,  0.0371, -0.0541,\n",
      "          0.1213, -0.0236,  0.1364, -0.0021, -0.0430,  0.0416,  0.1321, -0.0226,\n",
      "          0.1188, -0.0710,  0.0916,  0.0582,  0.0160,  0.1139,  0.0228,  0.0353,\n",
      "          0.1043, -0.0674, -0.0171, -0.0582,  0.0366, -0.1502,  0.0432,  0.0313,\n",
      "          0.0278, -0.0679,  0.0450,  0.0599,  0.0778,  0.0715,  0.0508,  0.0786,\n",
      "          0.0661, -0.0228, -0.0628, -0.0059, -0.0038,  0.0739,  0.1296,  0.0487,\n",
      "          0.0478, -0.0329,  0.1004,  0.0067, -0.0269,  0.0900, -0.0199, -0.0938,\n",
      "          0.0399,  0.0872, -0.0234,  0.0548,  0.0340,  0.1076, -0.0628, -0.0904,\n",
      "         -0.0064,  0.0843, -0.1209, -0.0144,  0.0561, -0.1339,  0.0366,  0.0232,\n",
      "          0.0402,  0.1247,  0.0588,  0.0049, -0.0368,  0.0090, -0.0888,  0.0168,\n",
      "         -0.0606, -0.1415,  0.1133,  0.0063,  0.0976,  0.0563, -0.0846, -0.0647]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450], requires_grad=True) \n",
      " tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "line_tensor[i]: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "hidden: tensor([[ 0.1095,  0.1130, -0.0195, -0.0279,  0.0018, -0.0020,  0.0734,  0.0440,\n",
      "         -0.0467, -0.0346, -0.0552, -0.0121,  0.0493, -0.0390, -0.0163, -0.0089,\n",
      "         -0.0549, -0.0002, -0.0903,  0.0381, -0.1124,  0.0003, -0.1345,  0.0892,\n",
      "         -0.0356,  0.0980,  0.0374, -0.0162,  0.0112, -0.0899, -0.0117,  0.0144,\n",
      "          0.0710,  0.1618,  0.1076,  0.0397, -0.1312, -0.0395, -0.1115, -0.0065,\n",
      "          0.0492,  0.0673,  0.0102,  0.0056, -0.0145,  0.0149,  0.0916, -0.0116,\n",
      "          0.1356,  0.0445,  0.1179, -0.0937, -0.0279,  0.0764, -0.0091, -0.0089,\n",
      "          0.1103, -0.0389,  0.0041, -0.0395,  0.0226,  0.0510,  0.0169,  0.0380,\n",
      "          0.1190, -0.0660, -0.0145, -0.1601,  0.0115, -0.1327, -0.1041,  0.0541,\n",
      "         -0.0519, -0.0588, -0.0877,  0.0566,  0.0593,  0.1062,  0.0782,  0.1373,\n",
      "          0.1356, -0.0927, -0.0359, -0.0684,  0.0216,  0.0299, -0.0104,  0.0760,\n",
      "         -0.0105,  0.0494,  0.1042,  0.0940,  0.0657,  0.1236,  0.0019, -0.1046,\n",
      "         -0.0472, -0.0401,  0.0134, -0.0160,  0.0478,  0.1212, -0.1386,  0.0730,\n",
      "          0.0676,  0.0778, -0.0183, -0.0471,  0.0939, -0.0181, -0.0765, -0.0728,\n",
      "          0.0463,  0.1169, -0.0669,  0.0211, -0.0237,  0.0651,  0.0231,  0.0556,\n",
      "         -0.0855, -0.2168,  0.0750, -0.0327,  0.0498, -0.0460,  0.0552, -0.0703]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]]) \n",
      " p.grad tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450], requires_grad=True) \n",
      " tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450]) \n",
      " p.grad tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0487, -0.0029,  0.0215,  ..., -0.0342, -0.0500,  0.0516],\n",
      "        [ 0.0555,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0504],\n",
      "        [-0.0063,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0278,  0.0666]]) \n",
      " p.grad tensor([[ 0.0017,  0.0000,  0.0417,  ...,  0.0016, -0.0027, -0.0027],\n",
      "        [-0.0054,  0.0000, -0.0604,  ..., -0.0040,  0.0045,  0.0048],\n",
      "        [-0.0080,  0.0000, -0.0544,  ..., -0.0034,  0.0037,  0.0043],\n",
      "        ...,\n",
      "        [ 0.0072,  0.0000, -0.0179,  ..., -0.0004,  0.0021,  0.0003],\n",
      "        [ 0.0116,  0.0000,  0.0606,  ...,  0.0059, -0.0046, -0.0063],\n",
      "        [-0.0044,  0.0000, -0.0762,  ..., -0.0051,  0.0062,  0.0057]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0695,  0.0573, -0.0513, -0.0304, -0.0141,  0.0240,  0.0358,  0.0673,\n",
      "         0.0299, -0.0436, -0.0103, -0.0039, -0.0025, -0.0583, -0.0117,  0.0387,\n",
      "        -0.0128, -0.0346, -0.0342,  0.0145, -0.0354, -0.0725, -0.0429, -0.0177,\n",
      "        -0.0032,  0.0558, -0.0438, -0.0464, -0.0044, -0.0641, -0.0181,  0.0502,\n",
      "        -0.0181,  0.0678,  0.0513, -0.0073, -0.0698, -0.0238, -0.0731,  0.0093,\n",
      "        -0.0126, -0.0072,  0.0698, -0.0189,  0.0197,  0.0163,  0.0393, -0.0580,\n",
      "         0.0283,  0.0285,  0.0603, -0.0466,  0.0271,  0.0645,  0.0554,  0.0219,\n",
      "         0.0489, -0.0659,  0.0662, -0.0064,  0.0300,  0.0396,  0.0397,  0.0251,\n",
      "         0.0321, -0.0560,  0.0175, -0.0623,  0.0598, -0.0604, -0.0365,  0.0394,\n",
      "        -0.0597, -0.0049,  0.0092,  0.0064,  0.0478,  0.0687,  0.0229,  0.0695,\n",
      "         0.0710, -0.0037, -0.0256,  0.0291,  0.0403,  0.0066,  0.0707,  0.0354,\n",
      "        -0.0365, -0.0306,  0.0195,  0.0647,  0.0055,  0.0278, -0.0470, -0.0512,\n",
      "        -0.0032,  0.0300,  0.0325,  0.0480,  0.0191,  0.0624, -0.0681, -0.0262,\n",
      "        -0.0034,  0.0446, -0.0724, -0.0401, -0.0021, -0.0301, -0.0049, -0.0168,\n",
      "         0.0193, -0.0137,  0.0265, -0.0095, -0.0604,  0.0527, -0.0607,  0.0012,\n",
      "        -0.0355, -0.0570,  0.0617, -0.0062,  0.0703,  0.0462,  0.0205, -0.0417]) \n",
      " p.grad tensor([ 0.0341, -0.0647, -0.0468, -0.0080,  0.0447,  0.0695, -0.1052, -0.0505,\n",
      "        -0.0452,  0.0586,  0.0464,  0.0359,  0.0454, -0.0561,  0.0168,  0.0745,\n",
      "        -0.0941, -0.0644,  0.0368,  0.0025,  0.0216, -0.0234,  0.0534,  0.0147,\n",
      "        -0.0118, -0.0009, -0.0250, -0.0200,  0.0799,  0.0333, -0.0314,  0.0396,\n",
      "        -0.0081,  0.0019,  0.0718, -0.1081, -0.0271, -0.1078, -0.0995, -0.0662,\n",
      "         0.0876,  0.0059,  0.0777, -0.0559, -0.0141,  0.0352,  0.0191, -0.0063,\n",
      "         0.0288,  0.1032, -0.0332,  0.0169, -0.0471, -0.0650,  0.0219, -0.0063,\n",
      "        -0.1192, -0.0202,  0.0190, -0.0132,  0.0025,  0.0399,  0.0316,  0.0467,\n",
      "         0.0304, -0.0092,  0.0622,  0.0282,  0.0377, -0.0232,  0.0457,  0.0358,\n",
      "         0.0138, -0.0016, -0.0385,  0.0108, -0.0745,  0.0516, -0.0259,  0.0004,\n",
      "         0.0257,  0.0265,  0.1175, -0.0624, -0.0486,  0.0075,  0.1172,  0.0429,\n",
      "         0.0184, -0.0063,  0.0936,  0.0119, -0.0333,  0.0182, -0.0260,  0.0044,\n",
      "         0.0115,  0.0364,  0.0760, -0.0187,  0.0056, -0.0001,  0.0715, -0.0363,\n",
      "         0.0549,  0.0694,  0.0825,  0.0081, -0.0460,  0.0561, -0.0755, -0.0620,\n",
      "        -0.0506,  0.0638, -0.0139, -0.0408, -0.0121, -0.0063, -0.0461, -0.0396,\n",
      "         0.0966,  0.0465,  0.0236, -0.1043,  0.0854, -0.0244,  0.0972, -0.0808])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0517]]) \n",
      " p.grad tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0025,  0.0029, -0.0037],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0026,  0.0032, -0.0040],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0026,  0.0032, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0025,  0.0029, -0.0038],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0435, -0.0522,  0.0665],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0026,  0.0032, -0.0040]])\n",
      "Parameter containing:\n",
      "tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450], requires_grad=True) \n",
      " tensor([-0.0216,  0.0478, -0.0223,  0.0058,  0.0522, -0.0163,  0.0486,  0.0325,\n",
      "        -0.0622, -0.0286,  0.0607,  0.0270,  0.0196,  0.0153, -0.0633,  0.0474,\n",
      "        -0.0574, -0.0450]) \n",
      " p.grad tensor([ 0.0533,  0.0575,  0.0576,  0.0581,  0.0554,  0.0559,  0.0497,  0.0603,\n",
      "         0.0512,  0.0536,  0.0563,  0.0626,  0.0579,  0.0540,  0.0517,  0.0534,\n",
      "        -0.9459,  0.0573])\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.005  # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    output = torch.tensor([0])\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "#         output, hidden = rnn(line_tensor[i], hidden)\n",
    "        print('line_tensor[i]:', line_tensor[i])\n",
    "        print('hidden:', hidden)\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "#         print(output)\n",
    "        for p in rnn.parameters():\n",
    "            print(p, '\\n', p.data, '\\n', 'p.grad', p.grad)\n",
    "    \n",
    "    loss = criterion(output, category_tensor)\n",
    "#     print(line_tensor)\n",
    "#     print(output)\n",
    "#     print(category_tensor)\n",
    "#     print(loss.item())\n",
    "    loss.backward()\n",
    "    \n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        print(p, '\\n', p.data, '\\n', 'p.grad', p.grad)\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return output, loss.item()\n",
    "\n",
    "category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "output, loss = train(category_tensor, line_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "# output, loss = train(category_tensor, line_tensor)\n",
    "line_tensor.size()\n",
    "line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0486, -0.0029,  0.0215,  ..., -0.0342, -0.0499,  0.0516],\n",
      "        [ 0.0554,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0505],\n",
      "        [-0.0064,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0279,  0.0666]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0310,  0.0040, -0.0287,  ...,  0.0083, -0.0709,  0.0524],\n",
      "        [-0.0486, -0.0029,  0.0215,  ..., -0.0342, -0.0499,  0.0516],\n",
      "        [ 0.0554,  0.0391,  0.0420,  ..., -0.0677, -0.0369, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0317,  0.0150, -0.0548,  ...,  0.0349, -0.0205, -0.0505],\n",
      "        [-0.0064,  0.0693,  0.0316,  ..., -0.0617, -0.0394,  0.0590],\n",
      "        [ 0.0260, -0.0350, -0.0186,  ...,  0.0293,  0.0279,  0.0666]]) \n",
      " p.grad tensor([[-1.8914e-03,  0.0000e+00,  0.0000e+00,  ..., -5.8281e-04,\n",
      "         -3.1477e-03, -3.5154e-03],\n",
      "        [ 2.1687e-02,  0.0000e+00,  0.0000e+00,  ..., -9.4150e-04,\n",
      "          3.4056e-03,  2.4507e-03],\n",
      "        [-1.0367e-02,  0.0000e+00,  0.0000e+00,  ...,  3.9776e-04,\n",
      "         -5.1309e-03, -5.0810e-03],\n",
      "        ...,\n",
      "        [-3.6906e-03,  0.0000e+00,  0.0000e+00,  ..., -8.1060e-04,\n",
      "         -3.1289e-03, -3.3880e-03],\n",
      "        [-9.2708e-03,  0.0000e+00,  0.0000e+00,  ...,  6.3743e-04,\n",
      "         -4.6049e-04, -1.7117e-05],\n",
      "        [-1.4152e-03,  0.0000e+00,  0.0000e+00,  ...,  7.6731e-04,\n",
      "         -8.5680e-04, -8.3367e-04]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0696,  0.0572, -0.0509, -0.0301, -0.0144,  0.0244,  0.0353,  0.0674,\n",
      "         0.0296, -0.0438, -0.0110, -0.0036, -0.0022, -0.0585, -0.0117,  0.0382,\n",
      "        -0.0123, -0.0345, -0.0336,  0.0139, -0.0349, -0.0728, -0.0431, -0.0180,\n",
      "        -0.0031,  0.0555, -0.0442, -0.0465, -0.0048, -0.0640, -0.0178,  0.0505,\n",
      "        -0.0182,  0.0673,  0.0516, -0.0081, -0.0697, -0.0236, -0.0733,  0.0093,\n",
      "        -0.0120, -0.0072,  0.0707, -0.0186,  0.0204,  0.0162,  0.0396, -0.0579,\n",
      "         0.0280,  0.0282,  0.0597, -0.0468,  0.0276,  0.0643,  0.0559,  0.0214,\n",
      "         0.0487, -0.0661,  0.0657, -0.0059,  0.0301,  0.0394,  0.0394,  0.0250,\n",
      "         0.0317, -0.0560,  0.0168, -0.0619,  0.0599, -0.0603, -0.0367,  0.0394,\n",
      "        -0.0600, -0.0053,  0.0086,  0.0064,  0.0474,  0.0691,  0.0230,  0.0698,\n",
      "         0.0711, -0.0039, -0.0262,  0.0287,  0.0404,  0.0060,  0.0703,  0.0359,\n",
      "        -0.0364, -0.0311,  0.0190,  0.0644,  0.0058,  0.0284, -0.0463, -0.0517,\n",
      "        -0.0031,  0.0292,  0.0320,  0.0481,  0.0186,  0.0618, -0.0676, -0.0263,\n",
      "        -0.0033,  0.0451, -0.0731, -0.0407, -0.0015, -0.0306, -0.0054, -0.0167,\n",
      "         0.0201, -0.0131,  0.0260, -0.0102, -0.0601,  0.0528, -0.0602,  0.0006,\n",
      "        -0.0360, -0.0569,  0.0609, -0.0058,  0.0700,  0.0463,  0.0205, -0.0414],\n",
      "       requires_grad=True) \n",
      " tensor([ 0.0696,  0.0572, -0.0509, -0.0301, -0.0144,  0.0244,  0.0353,  0.0674,\n",
      "         0.0296, -0.0438, -0.0110, -0.0036, -0.0022, -0.0585, -0.0117,  0.0382,\n",
      "        -0.0123, -0.0345, -0.0336,  0.0139, -0.0349, -0.0728, -0.0431, -0.0180,\n",
      "        -0.0031,  0.0555, -0.0442, -0.0465, -0.0048, -0.0640, -0.0178,  0.0505,\n",
      "        -0.0182,  0.0673,  0.0516, -0.0081, -0.0697, -0.0236, -0.0733,  0.0093,\n",
      "        -0.0120, -0.0072,  0.0707, -0.0186,  0.0204,  0.0162,  0.0396, -0.0579,\n",
      "         0.0280,  0.0282,  0.0597, -0.0468,  0.0276,  0.0643,  0.0559,  0.0214,\n",
      "         0.0487, -0.0661,  0.0657, -0.0059,  0.0301,  0.0394,  0.0394,  0.0250,\n",
      "         0.0317, -0.0560,  0.0168, -0.0619,  0.0599, -0.0603, -0.0367,  0.0394,\n",
      "        -0.0600, -0.0053,  0.0086,  0.0064,  0.0474,  0.0691,  0.0230,  0.0698,\n",
      "         0.0711, -0.0039, -0.0262,  0.0287,  0.0404,  0.0060,  0.0703,  0.0359,\n",
      "        -0.0364, -0.0311,  0.0190,  0.0644,  0.0058,  0.0284, -0.0463, -0.0517,\n",
      "        -0.0031,  0.0292,  0.0320,  0.0481,  0.0186,  0.0618, -0.0676, -0.0263,\n",
      "        -0.0033,  0.0451, -0.0731, -0.0407, -0.0015, -0.0306, -0.0054, -0.0167,\n",
      "         0.0201, -0.0131,  0.0260, -0.0102, -0.0601,  0.0528, -0.0602,  0.0006,\n",
      "        -0.0360, -0.0569,  0.0609, -0.0058,  0.0700,  0.0463,  0.0205, -0.0414]) \n",
      " p.grad tensor([ 0.0116, -0.0100,  0.0368,  0.0302, -0.0218,  0.0403, -0.0496,  0.0209,\n",
      "        -0.0211, -0.0197, -0.0638,  0.0399,  0.0320, -0.0180, -0.0054, -0.0502,\n",
      "         0.0576,  0.0144,  0.0531, -0.0665,  0.0497, -0.0317, -0.0134, -0.0331,\n",
      "         0.0104, -0.0247, -0.0482, -0.0048, -0.0420,  0.0123,  0.0296,  0.0260,\n",
      "        -0.0164, -0.0499,  0.0318, -0.0796,  0.0107,  0.0174, -0.0218, -0.0022,\n",
      "         0.0524, -0.0025,  0.0915,  0.0282,  0.0677, -0.0178,  0.0353,  0.0029,\n",
      "        -0.0259, -0.0279, -0.0659, -0.0249,  0.0486, -0.0195,  0.0464, -0.0507,\n",
      "        -0.0167, -0.0239, -0.0493,  0.0526,  0.0043, -0.0233, -0.0289, -0.0064,\n",
      "        -0.0462, -0.0009, -0.0748,  0.0395,  0.0052,  0.0007, -0.0255,  0.0019,\n",
      "        -0.0315, -0.0337, -0.0617,  0.0001, -0.0353,  0.0333,  0.0180,  0.0312,\n",
      "         0.0091, -0.0261, -0.0620, -0.0391,  0.0133, -0.0575, -0.0382,  0.0537,\n",
      "         0.0121, -0.0441, -0.0483, -0.0240,  0.0240,  0.0583,  0.0636, -0.0471,\n",
      "         0.0140, -0.0826, -0.0479,  0.0062, -0.0481, -0.0623,  0.0444, -0.0086,\n",
      "         0.0062,  0.0437, -0.0693, -0.0601,  0.0575, -0.0489, -0.0453,  0.0090,\n",
      "         0.0773,  0.0602, -0.0437, -0.0618,  0.0295,  0.0114,  0.0464, -0.0535,\n",
      "        -0.0513,  0.0061, -0.0717,  0.0446, -0.0300,  0.0090, -0.0023,  0.0324])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0518]],\n",
      "       requires_grad=True) \n",
      " tensor([[ 0.0411, -0.0505,  0.0456,  ..., -0.0211,  0.0029, -0.0087],\n",
      "        [-0.0329,  0.0490,  0.0239,  ..., -0.0696,  0.0407,  0.0081],\n",
      "        [ 0.0168,  0.0279,  0.0015,  ...,  0.0397, -0.0625, -0.0603],\n",
      "        ...,\n",
      "        [-0.0699, -0.0620,  0.0286,  ..., -0.0394, -0.0131, -0.0557],\n",
      "        [-0.0069, -0.0319, -0.0400,  ..., -0.0082, -0.0639,  0.0734],\n",
      "        [-0.0594, -0.0560, -0.0479,  ..., -0.0631,  0.0496, -0.0518]]) \n",
      " p.grad tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0029, 0.0002, 0.0007],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0027, 0.0002, 0.0007],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0029, 0.0002, 0.0007],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0030, 0.0002, 0.0007],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0027, 0.0002, 0.0007],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0027, 0.0002, 0.0006]])\n",
      "Parameter containing:\n",
      "tensor([-0.0211,  0.0483, -0.0218,  0.0064,  0.0528, -0.0158,  0.0491,  0.0231,\n",
      "        -0.0617, -0.0281,  0.0613,  0.0277,  0.0202,  0.0158, -0.0628,  0.0480,\n",
      "        -0.0569, -0.0444], requires_grad=True) \n",
      " tensor([-0.0211,  0.0483, -0.0218,  0.0064,  0.0528, -0.0158,  0.0491,  0.0231,\n",
      "        -0.0617, -0.0281,  0.0613,  0.0277,  0.0202,  0.0158, -0.0628,  0.0480,\n",
      "        -0.0569, -0.0444]) \n",
      " p.grad tensor([ 0.0564,  0.0533,  0.0561,  0.0574,  0.0573,  0.0498,  0.0542, -0.9376,\n",
      "         0.0508,  0.0559,  0.0614,  0.0586,  0.0597,  0.0497,  0.0522,  0.0589,\n",
      "         0.0536,  0.0521])\n"
     ]
    }
   ],
   "source": [
    "category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "output, loss = train(category_tensor, line_tensor)\n",
    "# print(loss)\n",
    "# category\n",
    "# line_tensor\n",
    "# print(category_tensor)\n",
    "# print(line_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (0m 8s) 2.0207 Baik / Arabic ✗ (Korean)\n",
      "10000 10% (0m 17s) 1.2351 Trang / Chinese ✗ (Vietnamese)\n",
      "15000 15% (0m 25s) 1.5131 Michaud / French ✓\n",
      "20000 20% (0m 34s) 3.0535 Jordan / Irish ✗ (Polish)\n",
      "25000 25% (0m 42s) 1.0797 Murakami / Arabic ✗ (Japanese)\n",
      "30000 30% (0m 51s) 2.2508 Arian / Irish ✗ (Arabic)\n",
      "35000 35% (1m 0s) 2.1622 Trujillo / Italian ✗ (Spanish)\n",
      "40000 40% (1m 8s) 0.5339 Xie / Chinese ✓\n",
      "45000 45% (1m 16s) 1.0396 Bernard / French ✓\n",
      "50000 50% (1m 24s) 0.6939 An / Vietnamese ✓\n",
      "55000 55% (1m 33s) 0.1506 Yamamura / Japanese ✓\n",
      "60000 60% (1m 41s) 0.6029 Albuquerque / Portuguese ✓\n",
      "65000 65% (1m 50s) 2.4214 Janda / Czech ✗ (Polish)\n",
      "70000 70% (1m 59s) 0.2806 Gui / Chinese ✓\n",
      "75000 75% (2m 8s) 0.0259 Astrakhantsev / Russian ✓\n",
      "80000 80% (2m 16s) 0.8768 Svejkovsky / Czech ✓\n",
      "85000 85% (2m 24s) 1.2164 Fuchs / Portuguese ✗ (German)\n",
      "90000 90% (2m 33s) 3.2359 Smit / French ✗ (Dutch)\n",
      "95000 95% (2m 41s) 0.9262 Jordison / English ✓\n",
      "100000 100% (2m 49s) 0.8570 Wehner / German ✓\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "# n_iters = 10000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' %(m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "    \n",
    "    # print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, \n",
    "                                                timeSince(start), loss, line, guess, correct))\n",
    "        \n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My data for two-phase flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.02711</td>\n",
       "      <td>1.02736</td>\n",
       "      <td>1.02686</td>\n",
       "      <td>1.03026</td>\n",
       "      <td>1.02794</td>\n",
       "      <td>1.02596</td>\n",
       "      <td>1.02909</td>\n",
       "      <td>1.03059</td>\n",
       "      <td>1.02579</td>\n",
       "      <td>1.03026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54397</td>\n",
       "      <td>0.54465</td>\n",
       "      <td>0.54253</td>\n",
       "      <td>0.54360</td>\n",
       "      <td>0.54360</td>\n",
       "      <td>0.54218</td>\n",
       "      <td>0.54270</td>\n",
       "      <td>0.54080</td>\n",
       "      <td>0.53965</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.16582</td>\n",
       "      <td>0.15830</td>\n",
       "      <td>0.16184</td>\n",
       "      <td>0.16381</td>\n",
       "      <td>0.16471</td>\n",
       "      <td>0.16525</td>\n",
       "      <td>0.16791</td>\n",
       "      <td>0.16924</td>\n",
       "      <td>0.17181</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20836</td>\n",
       "      <td>0.20144</td>\n",
       "      <td>0.19702</td>\n",
       "      <td>0.19409</td>\n",
       "      <td>0.19562</td>\n",
       "      <td>0.19314</td>\n",
       "      <td>0.19567</td>\n",
       "      <td>0.19845</td>\n",
       "      <td>0.20544</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.18607</td>\n",
       "      <td>0.19869</td>\n",
       "      <td>0.19684</td>\n",
       "      <td>0.18523</td>\n",
       "      <td>0.18014</td>\n",
       "      <td>0.18466</td>\n",
       "      <td>0.18430</td>\n",
       "      <td>0.18570</td>\n",
       "      <td>0.18125</td>\n",
       "      <td>0.17865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18558</td>\n",
       "      <td>0.18349</td>\n",
       "      <td>0.18566</td>\n",
       "      <td>0.18451</td>\n",
       "      <td>0.18651</td>\n",
       "      <td>0.18654</td>\n",
       "      <td>0.18681</td>\n",
       "      <td>0.19088</td>\n",
       "      <td>0.19802</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.17047</td>\n",
       "      <td>0.18804</td>\n",
       "      <td>0.18990</td>\n",
       "      <td>0.19283</td>\n",
       "      <td>0.19455</td>\n",
       "      <td>0.18451</td>\n",
       "      <td>0.17885</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.17363</td>\n",
       "      <td>0.17020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18892</td>\n",
       "      <td>0.18201</td>\n",
       "      <td>0.18236</td>\n",
       "      <td>0.18670</td>\n",
       "      <td>0.18701</td>\n",
       "      <td>0.18644</td>\n",
       "      <td>0.18176</td>\n",
       "      <td>0.18024</td>\n",
       "      <td>0.17893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.41909</td>\n",
       "      <td>0.42145</td>\n",
       "      <td>0.42786</td>\n",
       "      <td>0.44190</td>\n",
       "      <td>0.45160</td>\n",
       "      <td>0.45377</td>\n",
       "      <td>0.45363</td>\n",
       "      <td>0.44845</td>\n",
       "      <td>0.45273</td>\n",
       "      <td>0.45544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26808</td>\n",
       "      <td>0.26800</td>\n",
       "      <td>0.26811</td>\n",
       "      <td>0.26701</td>\n",
       "      <td>0.26470</td>\n",
       "      <td>0.26405</td>\n",
       "      <td>0.26547</td>\n",
       "      <td>0.26552</td>\n",
       "      <td>0.26478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2        3        4        5        6        7  \\\n",
       "64  1.02711  1.02736  1.02686  1.03026  1.02794  1.02596  1.02909  1.03059   \n",
       "26  0.16582  0.15830  0.16184  0.16381  0.16471  0.16525  0.16791  0.16924   \n",
       "22  0.18607  0.19869  0.19684  0.18523  0.18014  0.18466  0.18430  0.18570   \n",
       "31  0.17047  0.18804  0.18990  0.19283  0.19455  0.18451  0.17885  0.17730   \n",
       "47  0.41909  0.42145  0.42786  0.44190  0.45160  0.45377  0.45363  0.44845   \n",
       "\n",
       "          8        9  ...     1491     1492     1493     1494     1495  \\\n",
       "64  1.02579  1.03026  ...  0.54397  0.54465  0.54253  0.54360  0.54360   \n",
       "26  0.17181  0.17730  ...  0.20836  0.20144  0.19702  0.19409  0.19562   \n",
       "22  0.18125  0.17865  ...  0.18558  0.18349  0.18566  0.18451  0.18651   \n",
       "31  0.17363  0.17020  ...  0.18892  0.18201  0.18236  0.18670  0.18701   \n",
       "47  0.45273  0.45544  ...  0.26808  0.26800  0.26811  0.26701  0.26470   \n",
       "\n",
       "       1496     1497     1498     1499  label  \n",
       "64  0.54218  0.54270  0.54080  0.53965      4  \n",
       "26  0.19314  0.19567  0.19845  0.20544      2  \n",
       "22  0.18654  0.18681  0.19088  0.19802      2  \n",
       "31  0.18644  0.18176  0.18024  0.17893      2  \n",
       "47  0.26405  0.26547  0.26552  0.26478      3  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_features_label = pd.read_csv('df_train_set_features_label_time_series.csv', index_col=0)\n",
    "df_features_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.02711, 1.02736, 1.02686, ..., 0.5408 , 0.53965, 4.     ],\n",
       "       [0.16582, 0.1583 , 0.16184, ..., 0.19845, 0.20544, 2.     ],\n",
       "       [0.18607, 0.19869, 0.19684, ..., 0.19088, 0.19802, 2.     ],\n",
       "       ...,\n",
       "       [1.03805, 1.04144, 1.03779, ..., 1.03351, 1.03535, 6.     ],\n",
       "       [0.23968, 0.23916, 0.23897, ..., 0.48296, 0.48725, 3.     ],\n",
       "       [1.03426, 1.03661, 1.0356 , ..., 1.03393, 1.0351 , 6.     ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([86, 1501])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(df_features_label.values, dtype=torch.double)\n",
    "data\n",
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0271, 1.0274, 1.0269,  ..., 0.5427, 0.5408, 0.5396],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class MY_RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(MY_RNN, self).__init__()\n",
    "        \n",
    "#         self.hidden_size = hidden_size\n",
    "        \n",
    "#         self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "#         self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "#     def forward(self, input, hidden):\n",
    "# #         combined = torch.cat((input, hidden), 1)\n",
    "#         print(hidden, ' ', hidden.size(), ' ', hidden.dtype)\n",
    "#         print(input, input.size())\n",
    "#         combined = torch.cat((input, hidden), 1)\n",
    "#         print(combined)\n",
    "        \n",
    "#         hidden = self.i2h(combined)\n",
    "#         output = self.i2o(combined)\n",
    "#         output = self.softmax(output)\n",
    "#         return output, hidden\n",
    "    \n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "# n_hidden = 128\n",
    "# my_rnn = MY_RNN(n_letters, n_hidden, n_categories)\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MY_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MY_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "#         combined = torch.cat((input, hidden), 1)\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_voltage = 1\n",
    "n_hidden = 256\n",
    "n_categories = 6\n",
    "my_rnn = MY_RNN(n_voltage, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005  # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "# def my_train(category_tensor, line_tensor):\n",
    "#     hidden = my_rnn.initHidden()\n",
    "    \n",
    "#     my_rnn.zero_grad()\n",
    "    \n",
    "# #     for i in range(line_tensor.size()[0]):\n",
    "# #         output, hidden = my_rnn(line_tensor[i], hidden)\n",
    "    \n",
    "#     output, hidden = my_rnn(line_tensor, hidden)\n",
    "    \n",
    "#     loss = criterion(output, category_tensor)\n",
    "# #     print(line_tensor)\n",
    "# #     print(output)\n",
    "# #     print(category_tensor)\n",
    "# #     print(loss.item())\n",
    "#     loss.backward()\n",
    "    \n",
    "#     # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    \n",
    "#     for p in my_rnn.parameters():\n",
    "#         print(p, '\\n', p.data, '\\n', p.grad)\n",
    "# #         p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "#         p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "#     return output, loss.item()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def my_train(category_tensor, line_tensor):\n",
    "    hidden = my_rnn.initHidden()\n",
    "\n",
    "    my_rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = my_rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in my_rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# category_tensor, line_tensor = data[0][-1:].to(dtype=torch.long), data[0][:-1].view(-1, 1, 1).to(dtype=torch.float32)\n",
    "# output, loss = my_train(category_tensor, line_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_tensor, line_tensor = data[0][-1:].to(dtype=torch.long), data[0][:-1].to(dtype=torch.float32)\n",
    "line_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8167099952697754"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_hidden = 128\n",
    "# hidden =torch.zeros(1, n_hidden)\n",
    "# input = torch.tensor([[0.5]])\n",
    "# output, nex_hidden = my_rnn(input, hidden)\n",
    "# # torch.cat((input, hidden), 1)\n",
    "\n",
    "category_tensor, line_tensor = data[0][-1:].to(dtype=torch.long), data[0][:-1].view(-1, 1, 1).to(dtype=torch.float32)\n",
    "output, loss = my_train(category_tensor, line_tensor)\n",
    "output\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stratified', 1)\n"
     ]
    }
   ],
   "source": [
    "# 数字1-6分别代表层状流、环状流、波状流、塞状流、弹状流和泡状流\n",
    "my_all_categories = ['stratified', 'annular', 'wave', 'plug', 'slug', 'bubble']\n",
    "\n",
    "def my_categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return my_all_categories[category_i], category_i + 1\n",
    "\n",
    "print(my_categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   4\n",
      "5   2\n",
      "5   2\n",
      "5   2\n",
      "5   3\n",
      "5   6\n",
      "2   1\n",
      "5   3\n",
      "5   5\n",
      "5   5\n",
      "5   1\n",
      "5   2\n",
      "5   4\n",
      "5   6\n",
      "5   2\n",
      "5   3\n",
      "2   1\n",
      "5   3\n",
      "5   6\n",
      "5   3\n",
      "2   2\n",
      "2   1\n",
      "5   5\n",
      "2   2\n",
      "5   4\n",
      "2   1\n",
      "5   3\n",
      "5   4\n",
      "5   5\n",
      "2   2\n",
      "2   2\n",
      "5   6\n",
      "5   6\n",
      "2   2\n",
      "2   4\n",
      "2   3\n",
      "2   1\n",
      "2   2\n",
      "2   1\n",
      "2   1\n",
      "2   3\n",
      "2   1\n",
      "5   5\n",
      "2   1\n",
      "5   4\n",
      "5   6\n",
      "5   6\n",
      "2   4\n",
      "2   3\n",
      "5   5\n",
      "2   3\n",
      "5   6\n",
      "5   4\n",
      "6   6\n",
      "6   5\n",
      "5   3\n",
      "5   4\n",
      "2   3\n",
      "5   6\n",
      "5   4\n",
      "6   5\n",
      "5   2\n",
      "5   6\n",
      "6   4\n",
      "5   4\n",
      "6   6\n",
      "6   3\n",
      "2   2\n",
      "6   6\n",
      "2   1\n",
      "6   3\n",
      "2   2\n",
      "2   1\n",
      "2   2\n",
      "6   5\n",
      "6   6\n",
      "6   5\n",
      "6   5\n",
      "6   5\n",
      "5   2\n",
      "5   4\n",
      "5   4\n",
      "2   1\n",
      "6   6\n",
      "5   3\n",
      "6   6\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 86\n",
    "print_every = 1\n",
    "plot_every = 1\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    \"\"\"record time from start to now in mm ss.\"\"\"\n",
    "    now = time.time()\n",
    "    s = now -since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category = int(df_features_label.values[iter - 1][-1])\n",
    "    category_tensor= data[iter - 1][-1:].to(dtype=torch.long) - 1\n",
    "    line_tensor = data[iter - 1][:-1].view(-1, 1, 1).to(dtype=torch.float32)\n",
    "    output, loss = my_train(category_tensor, line_tensor)\n",
    "    current_loss =+ loss\n",
    "    \n",
    "    # Print iter number, loss, regime and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = my_categoryFromOutput(output)\n",
    "#         corrent = '✓' if guess_i == category else '✗ (%s)' % category\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print(guess_i, ' ', category)\n",
    "#         print('%d %d%% (%s) %.4f / %s %s' % (iter, iter / n_iters * 100, \n",
    "#                 timeSince(start), loss, guess, correct))\n",
    "        \n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 1501])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test_features_label = pd.read_csv('df_test_set_feature_label_time_series.csv', index_col=0)\n",
    "# df_test_features_label.head()\n",
    "\n",
    "test_data = torch.tensor(df_test_features_label.values, dtype=torch.double)\n",
    "test_data.size()\n",
    "\n",
    "# category_tensor, line_tensor = test_data[0][-1:].to(dtype=torch.long), test_data[0][:-1].to(dtype=torch.float32)\n",
    "# line_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> tensor([[[0.5773]],\n",
      "\n",
      "        [[0.5764]],\n",
      "\n",
      "        [[0.5739]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5863]],\n",
      "\n",
      "        [[0.5889]],\n",
      "\n",
      "        [[0.5890]]])\n",
      "(-1.72) annular\n",
      "(-1.75) stratified\n",
      "(-1.78) bubble\n"
     ]
    }
   ],
   "source": [
    "def my_evaluate(line_tensor):\n",
    "    hidden = my_rnn.initHidden()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = my_rnn(line_tensor[i], hidden)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = my_evaluate(input_line)\n",
    "        \n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, my_all_categories[category_index]))\n",
    "            predictions.append([value, my_all_categories[category_index]])\n",
    "\n",
    "category_tensor, line_tensor = test_data[0][-1:].to(dtype=torch.long), test_data[0][:-1].view(-1, 1, 1).to(dtype=torch.float32)\n",
    "predict(line_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4% (0m 21s) / annular ✓\n",
      "2 9% (0m 21s) / wave ✓\n",
      "3 13% (0m 21s) / wave ✓\n",
      "4 18% (0m 21s) / wave ✓\n",
      "5 22% (0m 21s) / annular ✓\n",
      "6 27% (0m 21s) / annular ✓\n",
      "7 31% (0m 22s) / wave ✓\n",
      "8 36% (0m 22s) / annular ✓\n",
      "9 40% (0m 22s) / annular ✓\n",
      "10 45% (0m 22s) / annular ✓\n",
      "11 50% (0m 22s) / wave ✓\n",
      "12 54% (0m 22s) / wave ✓\n",
      "13 59% (0m 22s) / annular ✓\n",
      "14 63% (0m 23s) / annular ✓\n",
      "15 68% (0m 23s) / wave ✓\n",
      "16 72% (0m 23s) / annular ✓\n",
      "17 77% (0m 23s) / wave ✓\n",
      "18 81% (0m 23s) / annular ✓\n",
      "19 86% (0m 23s) / annular ✓\n",
      "20 90% (0m 23s) / annular ✓\n",
      "21 95% (0m 24s) / wave ✓\n",
      "22 100% (0m 24s) / wave ✓\n"
     ]
    }
   ],
   "source": [
    "n_iters = 22\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category = int(df_test_features_label.values[iter - 1][-1:])\n",
    "    line_tensor = data[iter - 1][:-1].view(-1, 1, 1).to(dtype=torch.float32)\n",
    "#     output, loss = my_train(category_tensor, line_tensor)\n",
    "#     current_loss =+ loss\n",
    "    output = my_evaluate(line_tensor)\n",
    "    \n",
    "    # Print iter number, loss, regime and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = my_categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) / %s %s' % (iter, iter / n_iters * 100, \n",
    "                timeSince(start), guess, correct))\n",
    "        \n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
